end_time_ridge <- Sys.time()
ridge_time <- end_time_ridge - start_time_ridge
ridge_time
# When 位 is small, ridge regression gives similar answers to OLS regression:
#residen.ridge.mod$lambda[61]
#summary(residen.ridge.mod)
print(residen.ridge.mod)
#MSE for holdout ridge
residen.ridge.mod<- glmnet(X.res[train_d,],
y.res[train_d],
alpha=0,
lambda=grid)
ridge.pred <- predict(residen.ridge.mod, s=0.1, newx=X.res[test_d,])
residen.ridgeMSE = mean((ridge.pred - y.res[test_d])^2)
residen.ridgeMSE
#CV model ridge
set.seed(2022)
start_time_cvridge <- Sys.time()
cv.out.ridge <- cv.glmnet(X.res[train_d,],
y.res[train_d],
alpha=0,
lambda=grid,
nfolds=10)
end_time_cvridge <- Sys.time()
cvridge_time <- end_time_cvridge - start_time_cvridge
cv.out.ridge$lambda.min
best_lambda_ridge <- cv.out.ridge$lambda.min
cvridge_time
plot(cv.out.ridge)
bestlam.ridge <- cv.out.ridge$lambda.min
ridge.pred <- predict(cv.out.ridge, s=bestlam.ridge, newx=X.res[test_d,])
cvridge_MSE = mean((ridge.pred - y.res[test_d])^2)
cvridge_MSE
#CV for LASSO
set.seed(2022)
start_time_cvlasso <- Sys.time()
cv.out.lasso <- cv.glmnet(X.res[train_d,],
y.res[train_d],
alpha=1,
lambda=grid,
nfolds=10)
end_time_cvlasso <- Sys.time()
cvlasso_time <- end_time_cvlasso - start_time_cvlasso
cvlasso_time
# find the minumum value of lambda
best_lambda_lasso = cv.out.lasso$lambda.min
best_lambda_lasso
plot(cv.out.lasso)
# Compute the test error for Lasso CV:
bestlam.lasso <- cv.out.lasso$lambda.min
lasso.pred <- predict(cv.out.lasso, s=bestlam.lasso, newx=X.res[test_d,])
cvlasso_MSE =  mean((lasso.pred - y.res[test_d])^2)
cvlasso_MSE
print("The MSEs are:")
c(RidgeHoldoutMSE = residen.ridgeMSE )
c(RidgeCrossValidationMSE = cvridge_MSE )
# build lasso regression models & calc time
start_time_ridge <- Sys.time()
residen.ridge.mod = glmnet(X.res, y.res, alpha=1, lambda=grid)
end_time_ridge <- Sys.time()
ridge_time <- end_time_ridge - start_time_ridge
ridge_time
#MSE for holdout LASSO
residen.ridge.mod<- glmnet(X.res[train_d,],
y.res[train_d],
alpha=1,
lambda=grid)
lasso.pred <- predict(residen.lasso.mod, s=0.1, newx=X.res[test_d,])
#MSE for holdout LASSO
residen.lasso.mod<- glmnet(X.res[train_d,],
y.res[train_d],
alpha=1,
lambda=grid)
lasso.pred <- predict(residen.lasso.mod, s=0.1, newx=X.res[test_d,])
residen.lasso = mean((lasso.pred  - y.res[test_d])^2)
residen.lasso
#MSE for holdout LASSO
residen.lasso.mod<- glmnet(X.res[train_d,],
y.res[train_d],
alpha=1,
lambda=grid)
lasso.pred <- predict(residen.lasso.mod, s=0.5, newx=X.res[test_d,])
residen.lasso = mean((lasso.pred  - y.res[test_d])^2)
residen.lasso
#MSE for holdout LASSO
residen.lasso.mod<- glmnet(X.res[train_d,],
y.res[train_d],
alpha=1,
lambda=grid)
lasso.pred <- predict(residen.lasso.mod, s=0.01, newx=X.res[test_d,])
residen.lasso = mean((lasso.pred  - y.res[test_d])^2)
residen.lasso
#MSE for holdout LASSO
residen.lasso.mod<- glmnet(X.res[train_d,],
y.res[train_d],
alpha=1,
lambda=grid)
lasso.pred <- predict(residen.lasso.mod, s=0.02, newx=X.res[test_d,])
residen.lasso = mean((lasso.pred  - y.res[test_d])^2)
residen.lasso
#MSE for holdout LASSO
residen.lasso.mod<- glmnet(X.res[train_d,],
y.res[train_d],
alpha=1,
lambda=grid)
lasso.pred <- predict(residen.lasso.mod, s=0.1, newx=X.res[test_d,])
residen.lasso = mean((lasso.pred  - y.res[test_d])^2)
residen.lasso
#MSE for holdout LASSO
residen.lasso.mod<- glmnet(X.res[train_d,],
y.res[train_d],
alpha=1,
lambda=grid)
lasso.pred <- predict(residen.lasso.mod, s=0.2, newx=X.res[test_d,])
residen.lasso = mean((lasso.pred  - y.res[test_d])^2)
residen.lasso
#MSE for holdout LASSO
residen.lasso.mod<- glmnet(X.res[train_d,],
y.res[train_d],
alpha=1,
lambda=grid)
lasso.pred <- predict(residen.lasso.mod, s=0.1, newx=X.res[test_d,])
residen.lasso = mean((lasso.pred  - y.res[test_d])^2)
residen.lasso
set.seed(2022)
#assign all vars except V104 and V105 to X.res
X.res = model.matrix(V104~.-V105, Residen)[,-1]
#X.res = as.matrix(Residen[,-109])[,-108]
y.res = Residen$V104
# head(X.res)
train_d = sample(1:nrow(X.res), 0.8*nrow(X.res))
test_d = -train_d
# create our own list of lambda values to try.
grid <- 10^seq(3, -1, length=100)
#MSE for holdout ridge
start_time_ridge <- Sys.time()
residen.ridge.mod<- glmnet(X.res[train_d,],
y.res[train_d],
alpha=0,
lambda=grid)
end_time_ridge <- Sys.time()
ridge_time <- end_time_ridge - start_time_ridge
ridge_time
ridge.pred <- predict(residen.ridge.mod, s=0.1, newx=X.res[test_d,])
residen.ridgeMSE = mean((ridge.pred - y.res[test_d])^2)
residen.ridgeMSE
#MSE for holdout LASSO
start_time_lasso <- Sys.time()
residen.lasso.mod<- glmnet(X.res[train_d,],
y.res[train_d],
alpha=1,
lambda=grid)
end_time_lasso <- Sys.time()
lasso_time <- end_time_lasso - start_time_lasso
lasso_time
lasso.pred <- predict(residen.lasso.mod, s=0.1, newx=X.res[test_d,])
residen.lasso = mean((lasso.pred  - y.res[test_d])^2)
residen.lasso
#MSE for holdout LASSO
start_time_lasso <- Sys.time()
residen.lasso.mod<- glmnet(X.res[train_d,],
y.res[train_d],
alpha=1,
lambda=grid)
end_time_lasso <- Sys.time()
lasso_time <- end_time_lasso - start_time_lasso
lasso_time
lasso.pred <- predict(residen.lasso.mod, s=0.1, newx=X.res[test_d,])
residen.lasso = mean((lasso.pred  - y.res[test_d])^2)
residen.lasso
library(glmnet)
park = read.csv("parkinsons.csv", header = TRUE, sep = ",")
#remove first col
park = park[,-1]
#convert into matrix
park = as.data.frame(park)
#standardise model matrix as per question
park.scaled = scale(park)
park.scaled = as.data.frame(park.scaled)
#assign X and y values - for X removing col UPDRs (col98)
X.park = as.matrix(park.scaled[,-98])
y.park = park.scaled$UPDRS
# Linear model and summary.
linear.mod = lm(y.park  ~ X.park)
summary(linear.mod)
# set seed for reproducible results.
set.seed(2022, sample.kind = "Rounding")
# index 30 rows from park.scaled
#trainingRowIndex <- sample(1:nrow(X), 30)
#train <- sample(1:nrow(X), nrow(X)/2)
parkinsons_train = sample(1:nrow(X.park), (30/42)*nrow(X.park))
parkinsons_test = -parkinsons_train
linear.mod = lm(y.park[parkinsons_train] ~ X.park[parkinsons_train,])
summary(linear.mod)
linear.pred = coef(linear.mod)[1] + X.park[parkinsons_test,] %*% coef(linear.mod)[-1]
mean((linear.pred - y.park[parkinsons_test])^2)
# set seed for reproducible results.
set.seed(2022, sample.kind = "Rounding")
# index 30 rows from park.scaled
#trainingRowIndex <- sample(1:nrow(X), 30)
#train <- sample(1:nrow(X), nrow(X)/2)
parkinsons_train = sample(1:nrow(X.park), (30/42)*nrow(X.park))
parkinsons_test = -parkinsons_train
linear.mod = lm(y.park[parkinsons_train] ~ X.park[parkinsons_train,])
summary(linear.mod)
# set seed for reproducible results.
set.seed(2022)
# index 30 rows from park.scaled
#trainingRowIndex <- sample(1:nrow(X), 30)
#train <- sample(1:nrow(X), nrow(X)/2)
parkinsons_train = sample(1:nrow(X.park), (30/42)*nrow(X.park))
parkinsons_test = -parkinsons_train
linear.mod = lm(y.park[parkinsons_train] ~ X.park[parkinsons_train,])
summary(linear.mod)
#standardise model matrix as per question
park.scaled = scale(park)
park.scaled = as.data.frame(park.scaled)
#assign X and y values - for X removing col UPDRs (col98)
X.park = as.matrix(park.scaled[,-98])
y.park = park.scaled$UPDRS
# set seed for reproducible results.
set.seed(2022)
parkinsons_train = sample(1:nrow(X.park), (30/42)*nrow(X.park))
parkinsons_test = -parkinsons_train
linear.mod = lm(y.park[parkinsons_train] ~ X.park[parkinsons_train,])
summary(linear.mod)
# create our own list of lambda values to try.
grid <- 10^seq(3, -1, length=100)
# alpha=1 means to do the lasso.
lasso.mod <- glmnet(X.park,
y.park,
alpha=1,
lambda=grid,
thresh=1e-10)
# When 位 is small, the lasso gives similar answers to the OLS estimates:
lasso.mod$lambda[100]
# Cross-validation for the LASSO.- to find the best lambda value
set.seed(2022)
cv.out <- cv.glmnet(X.park[parkinsons_train,],
y.park[parkinsons_train],
alpha=1,
lambda=grid,
nfolds=30,
thresh=1e-10)
# find the minumum value of lambda
cv.out$lambda.min
# create our own list of lambda values to try.
grid <- 10^seq(3, -1, length=100)
# alpha=1 means to do the lasso.
lasso.mod <- glmnet(X.park[parkinsons_train,],
y.park[parkinsons_train],
alpha=1,
lambda=grid,
thresh=1e-10)
# When 位 is small, the lasso gives similar answers to the OLS estimates:
lasso.mod$lambda[100]
# Cross-validation for the LASSO.- to find the best lambda value
set.seed(2022)
cv.out <- cv.glmnet(X.park[parkinsons_train,],
y.park[parkinsons_train],
alpha=1,
lambda=grid,
nfolds=30,
thresh=1e-10)
# find the minumum value of lambda
cv.out$lambda.min
# Cross-validation for the LASSO.- to find the best lambda value
set.seed(2022)
cv.out <- cv.glmnet(X.park[parkinsons_train,],
y.park[parkinsons_train],
alpha=1,
lambda=grid,
nfolds=30,
thresh=1e-10)
# find the minumum value of lambda
cv.out$lambda.min
# create our own list of lambda values to try.
grid <- 10^seq(3, -1, length=100)
# Cross-validation for the LASSO.- to find the best lambda value
set.seed(2022)
cv.out <- cv.glmnet(X.park[parkinsons_train,],
y.park[parkinsons_train],
alpha=1,
lambda=grid,
nfolds=30,
thresh=1e-10)
# find the minumum value of lambda
cv.out$lambda.min
# create our own list of lambda values to try.
grid <- 10^seq(3, -1, length=100)
# Cross-validation for the LASSO.- to find the best lambda value
set.seed(2022)
cv.out <- cv.glmnet(X.park[parkinsons_train,],
y.park[parkinsons_train],
alpha=1,
lambda=grid,
nfolds=30,
grouped=FALSE,
thresh=1e-10)
# find the minumum value of lambda
cv.out$lambda.min
plot(cv.out)
# Compute the test eorr:
bestlam <- cv.out$lambda.min
lasso.pred <- predict(cv.out, s=bestlam, newx=X.park[parkinsons_test,])
mean((lasso.pred - y.park[parkinsons_test])^2)
# Compute the test error:
bestlam <- cv.out$lambda.min
lasso.pred <- predict(cv.out, s=bestlam, newx=X.park[parkinsons_test,])
mean((lasso.pred - y.park[parkinsons_test])^2)
# Finally, we refit on the full dataset using 位 min.
out = glmnet(X.park, y.park, alpha=1, lambda=grid, thresh=1e-12)
# small lambda, give the smallest MSE, all coefficients non-zero.
predict(out, type="coefficients", s=bestlam)
#this is the full model
set.seed(524)
# create the train and test datasets.
parkinsons_train2 <- sample(1:nrow(parkinsons_scaled), (30/42)*nrow(parkinsons_scaled))
set.seed(524)
# create the train and test datasets.
parkinsons_train2 <- sample(1:nrow(park.scaled ), (30/42)*nrow(park.scaled ))
parkinsons_test2 <- -parkinsons_train2
grid <- 10^seq(3, -1, length=100)
parkinsons_cv_lasso2 <- cv.glmnet(x.parkinsons[parkinsons_train2,]
, y.parkinsons[parkinsons_train2]
, alpha=1
, lambda=grid
, nfolds=30
, thresh=1e-10
, grouped=FALSE)
set.seed(524)
# create the train and test datasets.
parkinsons_train2 <- sample(1:nrow(park.scaled ), (30/42)*nrow(park.scaled ))
parkinsons_test2 <- -parkinsons_train2
grid <- 10^seq(3, -1, length=100)
parkinsons_cv_lasso2 <- cv.glmnet(X.park[parkinsons_train2,]
, y.park[parkinsons_train2]
, alpha=1
, lambda=grid
, nfolds=30
, thresh=1e-10
, grouped=FALSE)
best_lambda_parkinsons_lasso2 <- parkinsons_cv_lasso2$lambda.min
best_lambda_parkinsons_lasso2
parkinsons_lasso.pred2 <- predict(parkinsons_cv_lasso2
, s=best_lambda_parkinsons_lasso2
, newx=x.parkinsons[parkinsons_test2,])
set.seed(524)
# create the train and test datasets.
parkinsons_train2 <- sample(1:nrow(park.scaled ), (30/42)*nrow(park.scaled ))
parkinsons_test2 <- -parkinsons_train2
grid <- 10^seq(3, -1, length=100)
parkinsons_cv_lasso2 <- cv.glmnet(X.park[parkinsons_train2,]
, y.park[parkinsons_train2]
, alpha=1
, lambda=grid
, nfolds=30
, thresh=1e-10
, grouped=FALSE)
best_lambda_parkinsons_lasso2 <- parkinsons_cv_lasso2$lambda.min
best_lambda_parkinsons_lasso2
parkinsons_lasso.pred2 <- predict(parkinsons_cv_lasso2
, s=best_lambda_parkinsons_lasso2
, newx=X.park[parkinsons_test2,])
parkinsons_cvlasso_mse2 <- mean((parkinsons_lasso.pred2-y.parkinsons[parkinsons_test2])^2)
set.seed(524)
# create the train and test datasets.
parkinsons_train2 <- sample(1:nrow(park.scaled ), (30/42)*nrow(park.scaled ))
parkinsons_test2 <- -parkinsons_train2
grid <- 10^seq(3, -1, length=100)
parkinsons_cv_lasso2 <- cv.glmnet(X.park[parkinsons_train2,]
, y.park[parkinsons_train2]
, alpha=1
, lambda=grid
, nfolds=30
, thresh=1e-10
, grouped=FALSE)
best_lambda_parkinsons_lasso2 <- parkinsons_cv_lasso2$lambda.min
best_lambda_parkinsons_lasso2
parkinsons_lasso.pred2 <- predict(parkinsons_cv_lasso2
, s=best_lambda_parkinsons_lasso2
, newx=X.park[parkinsons_test2,])
parkinsons_cvlasso_mse2 <- mean((parkinsons_lasso.pred2-y.park[parkinsons_test2])^2)
parkinsons_cvlasso_mse2
parkinsons_lasso2 = glmnet(x.parkinsons, y.parkinsons, alpha=1, lambda=grid, thresh=1e-10)
set.seed(524)
# create the train and test datasets.
parkinsons_train2 <- sample(1:nrow(park.scaled ), (30/42)*nrow(park.scaled ))
parkinsons_test2 <- -parkinsons_train2
grid <- 10^seq(3, -1, length=100)
parkinsons_cv_lasso2 <- cv.glmnet(X.park[parkinsons_train2,]
, y.park[parkinsons_train2]
, alpha=1
, lambda=grid
, nfolds=30
, thresh=1e-10
, grouped=FALSE)
best_lambda_parkinsons_lasso2 <- parkinsons_cv_lasso2$lambda.min
best_lambda_parkinsons_lasso2
parkinsons_lasso.pred2 <- predict(parkinsons_cv_lasso2
, s=best_lambda_parkinsons_lasso2
, newx=X.park[parkinsons_test2,])
parkinsons_cvlasso_mse2 <- mean((parkinsons_lasso.pred2-y.park[parkinsons_test2])^2)
parkinsons_cvlasso_mse2
parkinsons_lasso2 = glmnet(X.park, y.park, alpha=1, lambda=grid, thresh=1e-10)
predict(parkinsons_lasso2, type="coefficients", s=best_lambda_parkinsons_lasso2)[1:98,]
set.seed(524)
# create the train and test datasets.
parkinsons_train2 <- sample(1:nrow(park.scaled ), (30/42)*nrow(park.scaled ))
parkinsons_test2 <- -parkinsons_train2
grid <- 10^seq(3, -1, length=100)
parkinsons_cv_lasso2 <- cv.glmnet(X.park[parkinsons_train2,]
, y.park[parkinsons_train2]
, alpha=1
, lambda=grid
, nfolds=30
, thresh=1e-10
, grouped=FALSE)
best_lambda_parkinsons_lasso2 <- parkinsons_cv_lasso2$lambda.min
best_lambda_parkinsons_lasso2
parkinsons_lasso.pred2 <- predict(parkinsons_cv_lasso2
, s=best_lambda_parkinsons_lasso2
, newx=X.park[parkinsons_test2,])
parkinsons_cvlasso_mse2 <- mean((parkinsons_lasso.pred2-y.park[parkinsons_test2])^2)
parkinsons_cvlasso_mse2
parkinsons_lasso2 = glmnet(X.park, y.park, alpha=1, lambda=grid, thresh=1e-10)
predict(parkinsons_lasso2, type="coefficients", s=best_lambda_parkinsons_lasso2)
install.packages("statmod")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("org.Hs.eg.db")
BiocManager::install("org.Hs.eg.db")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.15")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("org.Hs.eg.db")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.15")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("edgeR")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("GO.db")
install.packages("statmod")
#setwd("~/Documents/Carcinoma")   *** if necessary ***
rawdata <- read.delim("TableS1.txt", check.names=FALSE, stringsAsFactors=FALSE)
head(rawdata)
library(edgeR).
library(edgeR)
install.packages("edgeR")
version
R.version
R.version
install.packages("edgeR")
BiocManager::install("edgeR")
library(edgeR)
knitr::opts_chunk$set(echo = TRUE)
dat <- read.csv("Ass2Data.csv", header = TRUE, na.strings =
c('NA','-99', '--'), stringsAsFactors = TRUE)
summary(dat)
View(dat)
View(dat)
dat$POLITICS <- as.character(dat$POLITICS) #convert away from factor
data$POLITICS[is.na( data$POLITICS )] <- 'none'
dat$POLITICS <- as.character(dat$POLITICS) #convert away from factor
data$POLITICS[is.na(data$POLITICS)] <- 'none'
dat$POLITICS <- as.character(dat$POLITICS) #convert away from factor
dat$POLITICS[is.na(data$POLITICS)] <- "none"
dat$POLITICS <- as.character(dat$POLITICS) #convert away from factor
dat$POLITICS[is.na(dat$POLITICS)] <- "none"
dat$POLITICS <- as.factor(dat$POLITICS) # convert back to factor
shiny::runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 2/Assignment_2')
runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 2/Assignment_2')
install.packages("caret")
shiny::runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 3/The template shiny app code with which to do the assignment-20230506')
install.packages("shinyBS")
runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 3/The template shiny app code with which to do the assignment-20230506')
install.packages("doParallel")
runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 3/The template shiny app code with which to do the assignment-20230506')
install.packages("mixOmics")
runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 3/The template shiny app code with which to do the assignment-20230506')
install.packages("mixOmics")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("mixOmics")
runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 3/The template shiny app code with which to do the assignment-20230506')
version
R version
r version
R.Version()
runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 3/The template shiny app code with which to do the assignment-20230506')
R.version()
R.version
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("mixOmics")
shiny::runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 3/The template shiny app code with which to do the assignment-20230506')
install.packages("shinyBS")
runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 3/The template shiny app code with which to do the assignment-20230506')
runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 3/The template shiny app code with which to do the assignment-20230506')
install.packages("glmnet")
runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 3/The template shiny app code with which to do the assignment-20230506')
install.packages("caret")
shiny::runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 3/The template shiny app code with which to do the assignment-20230506')
install.packages("pls")
runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 3/The template shiny app code with which to do the assignment-20230506')
runApp('Library/CloudStorage/OneDrive-Personal/Desktop Onedrive/UNI MADS/DATA423 Industry/Assignment 3/The template shiny app code with which to do the assignment-20230506')
shiny::runApp()
